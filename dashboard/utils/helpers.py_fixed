""
Helper functions for dashboard data validation and processing.

This module provides utility functions for safe data handling,
timestamp conversion, and DataFrame validation.
""

import pandas as pd
import numpy as np
import logging
from typing import Any, Dict, List, Optional, Union
from datetime import datetime

logger = logging.getLogger(__name__)


def safe_get_column(df: pd.DataFrame, column_name: str, default_value: Any = None) -> pd.Series:
    ""
    Safely get a column from DataFrame with default fallback.

    Args:
        df: DataFrame to get column from
        column_name: Name of the column to retrieve
        default_value: Default value if column doesn't exist

    Returns:
        Column Series or Series with default values
    ""
    try:
        if df is None or df.empty:
            return pd.Series([default_value])

        if column_name in df.columns:
            return df[column_name]

        logger.warning(f"Column '{column_name}' not found in DataFrame, using default")
        return pd.Series([default_value] * len(df))

    except Exception as e:
        logger.error(f"Error getting column '{column_name}': {e}")
        return pd.Series([default_value])


def safe_dataframe_operation(df: pd.DataFrame, operation_name: str = "operation") -> pd.DataFrame:
    ""
    Perform safe DataFrame operations with error handling.

    Args:
        df: DataFrame to operate on
        operation_name: Name of the operation for logging

    Returns:
        Original DataFrame or empty DataFrame if operation fails
    ""
    try:
        if df is None:
            logger.warning(f"DataFrame is None for {operation_name}")
            return pd.DataFrame()

        if df.empty:
            logger.info(f"DataFrame is empty for {operation_name}")
            return df

        return df

    except Exception as e:
        logger.error(f"Error in DataFrame {operation_name}: {e}")
        return pd.DataFrame()


def validate_dataframe_columns(df: pd.DataFrame, required_columns: List[str],
                              default_values: Optional[Dict[str, Any]] = None) -> pd.DataFrame:
    ""
    Ensure DataFrame has all required columns with defaults.

    Args:
        df: DataFrame to validate
        required_columns: List of column names that must exist
        default_values: Dict mapping column names to default values

    Returns:
        DataFrame with all required columns
    ""
    try:
        if df is None or df.empty:
            # Create DataFrame with required columns
            df = pd.DataFrame()
            for col in required_columns:
                default_val = default_values.get(col, None) if default_values else None
                df[col] = [default_val]
            return df

        # Add missing columns with defaults
        for col in required_columns:
            if col not in df.columns:
                default_val = default_values.get(col, None) if default_values else None
                logger.info(f"Adding missing column '{col}' with default value: {default_val}")
                df[col] = default_val

        return df

    except Exception as e:
        logger.error(f"Error validating DataFrame columns: {e}")
        return pd.DataFrame()


def convert_timestamps_for_plotly(df: pd.DataFrame, timestamp_column: str = 'timestamp') -> pd.DataFrame:
    ""
    Convert timestamp columns to format suitable for Plotly.

    Args:
        df: DataFrame with timestamp column
        timestamp_column: Name of timestamp column

    Returns:
        DataFrame with converted timestamps
    ""
    try:
        if df is None or df.empty:
            return df

        if timestamp_column not in df.columns:
            logger.warning(f"Timestamp column '{timestamp_column}' not found")
            return df

        # Convert to datetime if not already
        df[timestamp_column] = pd.to_datetime(df[timestamp_column], errors='coerce')

        # Remove timezone info and convert to string format that Plotly likes
        # This avoids the FutureWarning about DatetimeProperties.to_pydatetime
        if hasattr(df[timestamp_column], 'dt'):
            # Use .values to get numpy array, then convert
            timestamps = df[timestamp_column].values
            df[timestamp_column] = timestamps

        return df

    except Exception as e:
        logger.error(f"Error converting timestamps for Plotly: {e}")
        return df


def safe_numeric_conversion(series: pd.Series, default_value: float = 0.0) -> pd.Series:
    ""
    Safely convert Series to numeric values.

    Args:
        series: Series to convert
        default_value: Default value for invalid entries

    Returns:
        Series with numeric values
    ""
    try:
        if series is None or series.empty:
            return pd.Series([default_value])

        return pd.to_numeric(series, errors='coerce').fillna(default_value)

    except Exception as e:
        logger.error(f"Error in numeric conversion: {e}")
        return pd.Series([default_value] * len(series))


def create_empty_dataframe_with_columns(columns: List[str],
                                       default_values: Optional[Dict[str, Any]] = None) -> pd.DataFrame:
    ""
    Create an empty DataFrame with specified columns and default values.

    Args:
        columns: List of column names
        default_values: Dict mapping column names to default values

    Returns:
        Empty DataFrame with specified columns
    ""
    try:
        df = pd.DataFrame()
        for col in columns:
            default_val = default_values.get(col, None) if default_values else None
            df[col] = [default_val] if default_val is not None else []
        return df

    except Exception as e:
        logger.error(f"Error creating empty DataFrame: {e}")
        return pd.DataFrame()


def safe_dict_access(data: Dict[str, Any], key: str, default_value: Any = None) -> Any:
    ""
    Safely access dictionary values with default fallback.

    Args:
        data: Dictionary to access
        key: Key to retrieve
        default_value: Default value if key doesn't exist

    Returns:
        Value from dict or default
    ""
    try:
        return data.get(key, default_value)
    except Exception as e:
        logger.error(f"Error accessing dict key '{key}': {e}")
        return default_value


def validate_and_clean_dataframe(df: pd.DataFrame, operation_name: str = "unknown") -> pd.DataFrame:
    ""
    Comprehensive DataFrame validation and cleaning.

    Args:
        df: DataFrame to validate and clean
        operation_name: Name of the operation for logging

    Returns:
        Validated and cleaned DataFrame
    ""
    try:
        # Check if DataFrame exists
        if df is None:
            logger.warning(f"DataFrame is None for {operation_name}")
            return pd.DataFrame()

        # Check if DataFrame is empty
        if df.empty:
            logger.info(f"DataFrame is empty for {operation_name}")
            return df

        # Remove duplicate rows
        original_len = len(df)
        df = df.drop_duplicates()
        if len(df) < original_len:
            logger.info(f"Removed {original_len - len(df)} duplicate rows from {operation_name}")

        # Reset index
        df = df.reset_index(drop=True)

        return df

    except Exception as e:
        logger.error(f"Error validating DataFrame for {operation_name}: {e}")
        return pd.DataFrame()
